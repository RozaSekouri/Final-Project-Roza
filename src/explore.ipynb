{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Smart Hotel Feedback System"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Focused Problems and Solutions for \"Smart Hotel Feedback System\"\n",
                "\n",
                "Core Focus Areas:\n",
                "\n",
                "*Identifying & Addressing Poor Performance (Departments/Aspects/Properties)\n",
                "\n",
                "*Optimizing Marketing & Highlighting Strengths\n",
                "\n",
                "*Strategic Competitive Benchmarking"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Problem 1: \"I don't want specific aspects or departments (like F&B or cleanliness) to consistently underperform and damage my brand's reputation.\"\n",
                "\n",
                "Expanded Problem Description: Hotel owners and managers need a way to pinpoint exactly where their service or facilities are failing to meet guest expectations. Negative feedback on critical areas can disproportionately affect overall brand perception and future bookings. This isn't just about general negative reviews, but identifying recurring issues in specific operational areas.\n",
                "\n",
                "Solution: Precision Performance Diagnostics via Aspect-Based Sentiment Analysis.\n",
                "\n",
                "By applying Aspect-Based Sentiment Analysis (ABSA), your system will automatically identify the specific hotel aspects (e.g., \"room cleanliness,\" \"Wi-Fi speed,\" \"front desk efficiency,\" \"breakfast quality,\" \"pool area\") that are consistently receiving negative sentiment.\n",
                "\n",
                "It will quantify the frequency and intensity of negative mentions for each aspect.\n",
                "\n",
                "For example: Your system could highlight that \"the breakfast buffet frequently receives low scores due to slow replenishment and cold food,\" or that \"the bathroom cleanliness in rooms is a recurring negative theme, especially in reviews mentioning older sections of the hotel.\"\n",
                "\n",
                "Actionable Output: This diagnostic capability directly enables targeted interventions (e.g., \"Implement new F&B protocols for hot food service at breakfast,\" \"Conduct deep cleaning audit for all bathrooms,\" \"Allocate more staff to busy check-in times\"). This avoids generic \"improve service\" directives and allows for specific, data-driven operational changes."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Problem 2: \"Our marketing isn't effectively highlighting what guests truly love, especially when it comes to unique dining experiences or property features, leading to missed opportunities.\"\n",
                "\n",
                "Expanded Problem Description: Hotels often struggle to identify their most appealing features from the guest's perspective. Traditional marketing relies on what the hotel thinks is good, but guest reviews reveal genuine delights and unique selling points (USPs) that might be overlooked. This includes standout experiences related to food and beverage.\n",
                "\n",
                "Solution: Discovery of \"Hidden Gems\" and Data-Driven Marketing Insights.\n",
                "\n",
                "Your system will leverage ABSA to identify specific aspects or amenities that consistently generate exceptionally high positive sentiment, even if they are not heavily promoted.\n",
                "\n",
                "It will identify unique phrases and keywords associated with these positive aspects.\n",
                "\n",
                "For example: Guests might consistently rave about \"the amazing omelette station at breakfast,\" \"the complimentary evening wine and cheese hour,\" \"the cozy rooftop bar with stunning views,\" or \"the unexpectedly delicious vegan options on the dinner menu.\" These are precise positive mentions beyond a general \"food was good.\"\n",
                "\n",
                "Actionable Output: This provides concrete, guest-validated Unique Selling Propositions (USPs) for marketing campaigns, website content, and social media promotion. It allows the hotel to craft targeted messages around what genuinely delights guests, attracting more bookings and commanding better pricing."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Problem 3: \"We don't know how our hotel truly stacks up against competitors, missing opportunities to capitalize on our strengths or address competitive weaknesses.\"\n",
                "\n",
                "Expanded Problem Description: In a competitive market, understanding your position relative to rivals is crucial. Hotels need real, data-driven insights into where they outperform or underperform competitors on specific aspects of the guest experience, not just overall ratings, to inform strategic decisions.\n",
                "\n",
                "Solution: Dynamic Competitive Benchmarking & Market Positioning.\n",
                "\n",
                "Requires Data: This solution hinges on acquiring guest review data for both your target hotel(s) and relevant competitors.\n",
                "\n",
                "Your system will apply ABSA across all collected hotels and then enable direct comparison of sentiment scores and frequency of mentions for various aspects across properties. This allows for granular benchmarking beyond simple star ratings.\n",
                "\n",
                "For example: \"Our hotel's 'Wi-Fi Speed' sentiment is 20% lower than Competitor A, but our 'Customer Service' sentiment is 15% higher than both Competitor A and B.\" Or, \"While Competitor C receives many positive mentions for 'parking,' our hotel has a strong lead in 'pool area amenities' sentiment.\"\n",
                "\n",
                "Actionable Output: This provides powerful strategic intelligence. It informs decisions on where to invest for competitive advantage (e.g., \"Prioritize Wi-Fi upgrades to close the gap with Competitor A, leveraging our strong service as a differentiator\"), where to focus marketing messages, and how to identify untapped market opportunities based on relative strengths and weaknesses. It allows hotels to actively manage their market position."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "let's break down how we can \"resolve\" them by moving into the practical data science steps.\n",
                "\n",
                "This will involve:\n",
                "\n",
                "Acquiring the Right Data (crucial for benchmarking).\n",
                "\n",
                "Preparing the Text Data.\n",
                "\n",
                "Building the Sentiment Models, especially for Aspect-Based Sentiment.\n",
                "\n",
                "Implementing the Benchmarking Logic.\n",
                "\n",
                "Generating Actionable Insights and Visualizations.\n",
                "\n",
                "Here’s a structured approach:\n",
                "\n",
                "Resolving the Focused Problems: Step-by-Step Implementation\n",
                "Phase 1: Data Acquisition & Loading (The Foundation)\n",
                "Goal: Secure a dataset of hotel reviews that allows for multi-hotel comparison.\n",
                "\n",
                "Find the Right Dataset:\n",
                "\n",
                "Priority: Search Kaggle for datasets like \"Hotel Reviews,\" \"Booking.com Hotel Reviews,\" or similar.\n",
                "\n",
                "Key Requirement: The dataset must include an identifier for the hotel (e.g., hotel_name, hotel_id, property_name) so you can distinguish reviews from different properties for benchmarking. A numerical rating column (e.g., 1-5 stars) is also highly beneficial for inferring overall sentiment.\n",
                "\n",
                "Language: Ensure the reviews are in the language you intend to analyze (e.g., English, Spanish).\n",
                "\n",
                "Volume: Aim for tens of thousands of reviews to enable robust analysis.\n",
                "\n",
                "Download to EC2 Instance:\n",
                "\n",
                "Once you've identified a suitable dataset on Kaggle, use your previously set up EC2 instance.\n",
                "\n",
                "Install Kaggle API client: pip install kaggle\n",
                "\n",
                "Transfer your kaggle.json API token to ~/.kaggle/ on your EC2 instance (chmod 600 ~/.kaggle/kaggle.json).\n",
                "\n",
                "Download the dataset:\n",
                "\n",
                "Bash\n",
                "\n",
                "mkdir hotel_reviews_data\n",
                "cd hotel_reviews_data\n",
                "kaggle datasets download -d <Kaggle_Dataset_Slug> # Replace with the actual slug\n",
                "unzip <downloaded_zip_file_name>.zip -d .\n",
                "ls -lh # Verify files\n",
                "Why EC2? This is much faster for large datasets than downloading locally and then uploading.\n",
                "\n",
                "Load Data into Pandas DataFrame:\n",
                "\n",
                "Use Python with Pandas on your EC2 instance (or later, a Jupyter environment if you set one up).\n",
                "\n",
                "Identify the CSV or JSON file containing the reviews.\n",
                "\n",
                "Python\n",
                "\n",
                "  import pandas as pd\n",
                "  # Adjust file path based on your downloaded data structure\n",
                "  df = pd.read_csv('path/to/your_hotel_reviews.csv')\n",
                "  # Or pd.read_json() if it's a JSON file\n",
                "  print(df.head())\n",
                "  print(df.info())\n",
                "Phase 2: Data Preprocessing & Initial EDA\n",
                "Goal: Clean and prepare the review text for NLP, and understand the dataset's characteristics.\n",
                "\n",
                "Initial Data Exploration (EDA):\n",
                "\n",
                "Review columns: Identify columns for review text, hotel ID, and rating (if available).\n",
                "\n",
                "Check for missing values: df.isnull().sum(). Decide how to handle them (drop rows, fill with placeholder).\n",
                "\n",
                "Check for duplicates: df.duplicated().sum(). Remove duplicate reviews if any.\n",
                "\n",
                "Review length distribution: Analyze average, min, max review lengths.\n",
                "\n",
                "Rating distribution: df['rating_column'].value_counts().plot(kind='bar') – essential for sentiment labeling.\n",
                "\n",
                "Text Preprocessing:\n",
                "\n",
                "Libraries: nltk (for tokenization, stop words, lemmatization), re (for regex cleaning), spaCy (alternative for advanced NLP).\n",
                "\n",
                "Steps (in order):\n",
                "\n",
                "Lowercase conversion: text.lower()\n",
                "\n",
                "Punctuation removal: re.sub(r'[^\\w\\s]', '', text)\n",
                "\n",
                "Number removal (optional): Decide if numbers (e.g., \"room 302\") are relevant for aspects.\n",
                "\n",
                "Tokenization: Split text into words (e.g., nltk.word_tokenize).\n",
                "\n",
                "Stop word removal: Remove common words (e.g., \"the\", \"is\", \"a\") that don't convey much meaning. Ensure you use a stop word list for the correct language.\n",
                "\n",
                "Lemmatization: Reduce words to their base form (e.g., \"running\" -> \"run\"). Better than stemming for accuracy.\n",
                "\n",
                "Handling Negation (Advanced): If \"not good\" should be treated differently from \"good,\" you might add a \"NOT_\" prefix to words following a negation (e.g., \"not_good\"). This usually requires a bit more logic.\n",
                "\n",
                "Create a new column for the cleaned review text.\n",
                "\n",
                "Phase 3: Sentiment Labeling & Feature Engineering\n",
                "Goal: Assign sentiment labels to reviews (if not already present) and transform text into numerical features for modeling.\n",
                "\n",
                "Sentiment Labeling (If reviews have ratings but no explicit sentiment):\n",
                "\n",
                "Map numerical ratings to sentiment categories. This is the most common approach.\n",
                "\n",
                "Example mapping (adjust based on your dataset's rating scale):\n",
                "\n",
                "1-2 stars: Negative\n",
                "\n",
                "3 stars: Neutral\n",
                "\n",
                "4-5 stars: Positive\n",
                "\n",
                "Create a new sentiment column based on this mapping.\n",
                "\n",
                "Analyze sentiment distribution: df['sentiment'].value_counts(). Be prepared for class imbalance (e.g., more positive reviews).\n",
                "\n",
                "Feature Engineering:\n",
                "\n",
                "TF-IDF (Term Frequency-Inverse Document Frequency): A robust baseline for text classification.\n",
                "\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "vectorizer = TfidfVectorizer(max_features=5000) (adjust max_features)\n",
                "\n",
                "X = vectorizer.fit_transform(df['cleaned_review_text'])\n",
                "\n",
                "Word Embeddings (Recommended for better performance): Word2Vec, GloVe, or FastText.\n",
                "\n",
                "These represent words as dense vectors, capturing semantic meaning.\n",
                "\n",
                "You can train your own on your corpus or use pre-trained embeddings (e.g., from spaCy, or specific pre-trained models for your language).\n",
                "\n",
                "To use with traditional ML models, you'd typically average the word vectors for each review.\n",
                "\n",
                "Phase 4: Aspect-Based Sentiment Analysis (ABSA)\n",
                "Goal: Identify specific aspects within reviews and determine the sentiment for those aspects. This is central to all three problems.\n",
                "\n",
                "This is the most complex part. For a bootcamp, a hybrid approach (rule-based aspect extraction + general sentiment model) is often most feasible:\n",
                "\n",
                "Define Aspects: Manually define a list of key hotel aspects (e.g., ['Cleanliness', 'Service', 'Location', 'Amenities', 'Value', 'Room', 'Check-in', 'Wi-Fi', 'Parking']).\n",
                "\n",
                "Aspect Keyword/Phrase List: For each aspect, list associated keywords and common phrases (e.g., Cleanliness: ['clean', 'dirty', 'spotless', 'smell', 'dust', 'bathroom', 'room cleanliness']).\n",
                "\n",
                "Sentence/Phrase Level Extraction & Sentiment:\n",
                "\n",
                "Iterate through each review.\n",
                "\n",
                "Divide reviews into sentences.\n",
                "\n",
                "For each sentence, check if it contains keywords from your aspect list. If it does, assign that sentence to the relevant aspect(s).\n",
                "\n",
                "Apply a sentence-level sentiment analysis model (e.g., a simple Naive Bayes, Logistic Regression trained on your labeled reviews, or a pre-trained sentiment lexicon like VADER) to each aspect-related sentence.\n",
                "\n",
                "Output: For each review, you'd have a list of identified aspects, and for each aspect, its associated sentiment (and potentially the original sentence snippet).\n",
                "\n",
                "Example Data Structure: {'review_id': 123, 'aspect': 'Cleanliness', 'sentiment': 'Negative', 'snippet': 'The bathroom was quite dirty.'}\n",
                "\n",
                "Phase 5: Model Training (for Sentiment Classification) & Benchmarking\n",
                "Goal: Train your sentiment model (if not using rule-based/VADER for sentence-level sentiment), and then apply the benchmarking logic.\n",
                "\n",
                "Train Overall Sentiment Model (Optional, or if ABSA uses a classifier):\n",
                "\n",
                "Split your data (reviews, not aspect-sentences) into training and test sets.\n",
                "\n",
                "Train a classification model (Logistic Regression, Naive Bayes, SVM, Random Forest) on your TF-IDF or Word Embedding features to predict the sentiment column.\n",
                "\n",
                "Evaluate using accuracy, precision, recall, f1-score, and a confusion matrix.\n",
                "\n",
                "Aggregate ABSA Results for Problem Solving:\n",
                "\n",
                "Now, use the aspect-sentiment data generated in Phase 4.\n",
                "\n",
                "For Problem 1 (Addressing Poor Performance):\n",
                "\n",
                "Group by aspect and calculate the count of Negative sentiments for each aspect.\n",
                "\n",
                "Identify aspects with the highest frequency of negative mentions.\n",
                "\n",
                "Output: \"Top 5 most negatively reviewed aspects.\"\n",
                "\n",
                "For Problem 2 (Highlighting Strengths):\n",
                "\n",
                "Group by aspect and calculate the count of Positive sentiments for each aspect.\n",
                "\n",
                "Identify aspects with the highest frequency of positive mentions.\n",
                "\n",
                "Analyze associated keywords/snippets for \"hidden gems.\"\n",
                "\n",
                "Output: \"Top 5 most positively reviewed aspects.\"\n",
                "\n",
                "For Problem 3 (Competitive Benchmarking):\n",
                "\n",
                "Group your aspect-sentiment data by both hotel_id AND aspect.\n",
                "\n",
                "Calculate the average sentiment score (e.g., if Positive=1, Neutral=0, Negative=-1) for each aspect, for each hotel.\n",
                "\n",
                "Output: A table showing Hotel A: Cleanliness: 0.8, Service: 0.6, Hotel B: Cleanliness: 0.5, Service: 0.9.\n",
                "\n",
                "Phase 6: Recommendation Generation & Dashboard\n",
                "Goal: Translate your analytical findings into actionable recommendations and present them clearly.\n",
                "\n",
                "Derive Actionable Recommendations:\n",
                "\n",
                "From Problem 1 (Underperformance): For each top negative aspect, formulate a concrete recommendation. Use the relevant review snippets as evidence. (e.g., \"Cleanliness: Bathroom – Implement deep cleaning audits for all bathrooms, specifically targeting grout and shower areas, as evidenced by 'dirty grout' and 'mold in shower' snippets.\")\n",
                "\n",
                "From Problem 2 (Hidden Gems): For each top positive aspect, suggest how marketing could leverage it. (e.g., \"Amenities: Rooftop Bar – Feature high-quality photos and guest testimonials about the 'stunning views' and 'cozy ambiance' in social media campaigns.\")\n",
                "\n",
                "From Problem 3 (Benchmarking): Based on the comparisons, recommend strategic moves. (e.g., \"Wi-Fi Speed: Competitor Analysis – Prioritize budget for network infrastructure upgrade to match Competitor A's superior Wi-Fi performance, as this is a key differentiator for modern guests.\")\n",
                "\n",
                "Develop a Dashboard/Report:\n",
                "\n",
                "Tool: Streamlit is highly recommended for its ease of use for interactive web apps. Plotly Dash or even a well-structured Jupyter Notebook with ipywidgets could also work.\n",
                "\n",
                "Key Visualizations:\n",
                "\n",
                "Overall sentiment distribution (pie chart/bar chart).\n",
                "\n",
                "Top N positive and negative aspects (bar charts based on frequency/sentiment).\n",
                "\n",
                "Word clouds for positive/negative keywords per aspect.\n",
                "\n",
                "For Benchmarking: Bar charts or radar charts comparing sentiment scores for key aspects across different hotels (e.g., a chart showing \"Cleanliness\" sentiment for Hotel A, B, C, D).\n",
                "\n",
                "Display example review snippets for identified aspects (positive and negative).\n",
                "\n",
                "Present your actionable recommendations clearly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Defaulting to user installation because normal site-packages is not writeable\n",
                        "Collecting kaggle\n",
                        "  Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting bleach (from kaggle)\n",
                        "  Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting certifi>=14.05.14 (from kaggle)\n",
                        "  Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.7/162.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting charset-normalizer (from kaggle)\n",
                        "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting idna (from kaggle)\n",
                        "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting protobuf (from kaggle)\n",
                        "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /home/vscode/.local/lib/python3.11/site-packages (from kaggle) (2.9.0.post0)\n",
                        "Collecting python-slugify (from kaggle)\n",
                        "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
                        "Collecting requests (from kaggle)\n",
                        "  Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hRequirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/site-packages (from kaggle) (67.8.0)\n",
                        "Requirement already satisfied: six>=1.10 in /home/vscode/.local/lib/python3.11/site-packages (from kaggle) (1.17.0)\n",
                        "Collecting text-unidecode (from kaggle)\n",
                        "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting tqdm (from kaggle)\n",
                        "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting urllib3>=1.15.1 (from kaggle)\n",
                        "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
                        "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hCollecting webencodings (from kaggle)\n",
                        "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
                        "Installing collected packages: webencodings, text-unidecode, urllib3, tqdm, python-slugify, protobuf, idna, charset-normalizer, certifi, bleach, requests, kaggle\n",
                        "Successfully installed bleach-6.2.0 certifi-2025.7.14 charset-normalizer-3.4.2 idna-3.10 kaggle-1.7.4.5 protobuf-6.31.1 python-slugify-8.0.4 requests-2.32.4 text-unidecode-1.3 tqdm-4.67.1 urllib3-2.5.0 webencodings-0.5.1\n",
                        "\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
                        "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "!pip install kaggle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'matplotlib'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
                    ]
                }
            ],
            "source": [
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "DataFrame loaded successfully!\n",
                        "\n",
                        "First 5 rows:\n",
                        "   Index             Name                  Area Review_Date  \\\n",
                        "0      0  Hotel The Pearl  Paharganj, New Delhi      Jul-23   \n",
                        "1      1  Hotel The Pearl  Paharganj, New Delhi      Aug-23   \n",
                        "2      2  Hotel The Pearl  Paharganj, New Delhi      Aug-23   \n",
                        "3      3  Hotel The Pearl  Paharganj, New Delhi      Aug-23   \n",
                        "4      4  Hotel The Pearl  Paharganj, New Delhi      Aug-23   \n",
                        "\n",
                        "                            Rating_attribute  Rating(Out of 10)  \\\n",
                        "0                 Best budget friendly hotel                9.0   \n",
                        "1                              Amazing place                9.0   \n",
                        "2               Overall good stay. Economic.                9.0   \n",
                        "3                                     Lovely                9.0   \n",
                        "4  Great hotel Great staff and great staying                9.0   \n",
                        "\n",
                        "                                         Review_Text  \n",
                        "0  Hotel the pearl is perfect place to stay in De...  \n",
                        "1  Location of the hotel is perfect. The hotel is...  \n",
                        "2                             Location, Indian food.  \n",
                        "3  The location and the hotel itself is great. Ne...  \n",
                        "4  Friendly and smiling staffs.. The reception st...  \n",
                        "\n",
                        "DataFrame Info (columns, non-null counts, dtypes):\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 7001 entries, 0 to 7000\n",
                        "Data columns (total 7 columns):\n",
                        " #   Column             Non-Null Count  Dtype  \n",
                        "---  ------             --------------  -----  \n",
                        " 0   Index              7001 non-null   int64  \n",
                        " 1   Name               7001 non-null   object \n",
                        " 2   Area               7001 non-null   object \n",
                        " 3   Review_Date        7001 non-null   object \n",
                        " 4   Rating_attribute   7001 non-null   object \n",
                        " 5   Rating(Out of 10)  7001 non-null   float64\n",
                        " 6   Review_Text        6994 non-null   object \n",
                        "dtypes: float64(1), int64(1), object(5)\n",
                        "memory usage: 383.0+ KB\n"
                    ]
                }
            ],
            "source": [
                "# Define the path to your unzipped CSV file.\n",
                "\n",
                "file_path = '../data_hotel_reviews/hotel_reviews.csv'\n",
                "\n",
                "# Load the CSV into a Pandas DataFrame\n",
                "try:\n",
                "    df = pd.read_csv(file_path) # Corrected line: call pd.read_csv with file_path\n",
                "    print(\"DataFrame loaded successfully!\")\n",
                "    print(\"\\nFirst 5 rows:\")\n",
                "    print(df.head())\n",
                "    print(\"\\nDataFrame Info (columns, non-null counts, dtypes):\")\n",
                "    df.info()\n",
                "except FileNotFoundError:\n",
                "    print(f\"Error: The file '{file_path}' was not found.\")\n",
                "    print(\"Please ensure your notebook is in the correct directory, or adjust the file path.\")\n",
                "except Exception as e:\n",
                "    print(f\"An error occurred while loading the DataFrame: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Detailed Missing Values Count:\n",
                        "Index                0\n",
                        "Name                 0\n",
                        "Area                 0\n",
                        "Review_Date          0\n",
                        "Rating_attribute     0\n",
                        "Rating(Out of 10)    0\n",
                        "Review_Text          7\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\nDetailed Missing Values Count:\")\n",
                "print(df.isnull().sum())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Number of Duplicate Rows:\n",
                        "Found 0 duplicate rows.\n",
                        "No duplicate rows found.\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\nNumber of Duplicate Rows:\")\n",
                "num_duplicates = df.duplicated().sum()\n",
                "print(f\"Found {num_duplicates} duplicate rows.\")\n",
                "\n",
                "if num_duplicates > 0:\n",
                "    print(\"Removing duplicate rows...\")\n",
                "    df.drop_duplicates(inplace=True)\n",
                "    print(f\"Duplicates removed. New DataFrame shape: {df.shape}\")\n",
                "else:\n",
                "    print(\"No duplicate rows found.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Review Length Distribution (descriptive statistics):\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'plt' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mreview_length\u001b[39m\u001b[33m'\u001b[39m].describe()\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Optional: Visualize review length distribution (requires matplotlib and seaborn)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mplt\u001b[49m.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m     11\u001b[39m sns.histplot(df[\u001b[33m'\u001b[39m\u001b[33mreview_length\u001b[39m\u001b[33m'\u001b[39m], bins=\u001b[32m50\u001b[39m, kde=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mDistribution of Review Lengths\u001b[39m\u001b[33m'\u001b[39m)\n",
                        "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
                    ]
                }
            ],
            "source": [
                "# Ensure 'Review_Text' column is not null before applying .apply(len)\n",
                "# df['Review_Text'].astype(str) handles any potential NaN values by converting them to 'nan' string\n",
                "df['review_length'] = df['Review_Text'].astype(str).apply(len)\n",
                "\n",
                "print(\"\\nReview Length Distribution (descriptive statistics):\")\n",
                "# Remove print() to let Jupyter display the DataFrame directly\n",
                "df['review_length'].describe()\n",
                "\n",
                "# Optional: Visualize review length distribution (requires matplotlib and seaborn)\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.histplot(df['review_length'], bins=50, kde=True)\n",
                "plt.title('Distribution of Review Lengths')\n",
                "plt.xlabel('Review Length (characters)')\n",
                "plt.ylabel('Number of Reviews')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
